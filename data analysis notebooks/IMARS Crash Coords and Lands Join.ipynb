{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "006183d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using NPS Lands Layer Package\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "    \n",
    "ALLCRASHES = pd.read_csv(r\"C:\\Users\\Christopher.Dettmer\\Documents\\TSP\\Using New Data\\IMARS_slim_clean_forChris.csv\")\n",
    "ALLBOUNDARIES=gpd.read_file(r\"C:\\Users\\Christopher.Dettmer\\Documents\\TSP\\Spatial Join Files\\nps_boundary.shp\")\n",
    "\n",
    "\n",
    "def crashChooser(ALLCRASHES,ALLBOUNDARIES,parkCode):\n",
    "        \n",
    "    #Take park crashes, turn into a dataframe with coords, change from geometric to projected coords for sjoin\n",
    "    park_crashes_df=ALLCRASHES.loc[ALLCRASHES['Park']==parkCode]\n",
    "    park_crashes=gpd.GeoDataFrame(park_crashes_df, geometry=gpd.points_from_xy(park_crashes_df.Longitude,park_crashes_df.Latitude))\n",
    "    proj_park_crashes=park_crashes.set_crs(epsg=3857)\n",
    "    \n",
    "    return proj_park_crashes\n",
    "\n",
    "def boundaryChooser(ALLCRASHES,ALLBOUNDARIES,parkCode):\n",
    "    \n",
    "    #Take park boundary(ies), change from geometric to projected coords for sjoin\n",
    "    park_polygon=ALLBOUNDARIES.loc[ALLBOUNDARIES['UNIT_CODE']==parkCode]\n",
    "    proj_park_polygon=park_polygon.set_crs(epsg=3857,allow_override=True)          \n",
    "        \n",
    "    return proj_park_polygon\n",
    "    \n",
    "\n",
    "def sjoin_0(proj_park_crashes, proj_park_polygon):\n",
    "    \n",
    "    return gpd.sjoin(proj_park_polygon,proj_park_crashes,how='left')\n",
    "\n",
    "\n",
    "def sjoin_1(proj_park_crashes, proj_park_polygon):\n",
    "    \n",
    "    #Take park boundary(ies) with projected coords, add buffer, then reformat to geodataseries\n",
    "    park_polygon_1_buffer_geoseries=gpd.GeoSeries.buffer(proj_park_polygon,0.0145055773)\n",
    "    park_polygon_1_buffer=gpd.GeoDataFrame(geometry=gpd.GeoSeries(park_polygon_1_buffer_geoseries))\n",
    "\n",
    "    return gpd.sjoin(park_polygon_1_buffer,proj_park_crashes,how='left')\n",
    "\n",
    "\n",
    "def sjoin_10(proj_park_crashes, proj_park_polygon):\n",
    "    \n",
    "    #Take park boundary(ies) with projected coords, add buffer, then reformat to geodataseries\n",
    "    park_polygon_10_buffer_geoseries=gpd.GeoSeries.buffer(proj_park_polygon,0.1450557739)\n",
    "    park_polygon_10_buffer=gpd.GeoDataFrame(geometry=gpd.GeoSeries(park_polygon_10_buffer_geoseries))\n",
    "\n",
    "    return gpd.sjoin(park_polygon_10_buffer,proj_park_crashes,how='left')\n",
    "\n",
    "\n",
    "def sjoin_100(proj_park_crashes, proj_park_polygon):\n",
    "    \n",
    "    #Take park boundary(ies) with projected coords, add buffer, then reformat to geodataseries\n",
    "    park_polygon_100_buffer_geoseries=gpd.GeoSeries.buffer(proj_park_polygon,1.45055774)\n",
    "    park_polygon_100_buffer=gpd.GeoDataFrame(geometry=gpd.GeoSeries(park_polygon_100_buffer_geoseries))\n",
    "\n",
    "    return gpd.sjoin(park_polygon_100_buffer,proj_park_crashes,how='left')\n",
    "\n",
    "\n",
    "def calculations(proj_park_crashes, proj_park_polygon, outputDataFrame, output_df_park, output_df_region):\n",
    "    \n",
    "    within0=len(sjoin_0(proj_park_crashes, proj_park_polygon))\n",
    "    within1=len(sjoin_1(proj_park_crashes, proj_park_polygon))\n",
    "    within10=len(sjoin_10(proj_park_crashes, proj_park_polygon))\n",
    "    within100=len(sjoin_100(proj_park_crashes, proj_park_polygon))\n",
    "    \n",
    "    totalCrashes=len(proj_park_crashes)\n",
    "    over100=totalCrashes-within100\n",
    "    over10=within100-within10\n",
    "    over1=within10-within1\n",
    "    over0=within1-within0\n",
    "    inBoundary=within0\n",
    "    \n",
    "    outputDataFrame.loc[len(outputDataFrame.index)]=[output_df_park,output_df_region,inBoundary,over0,over1,over10,over100,totalCrashes]\n",
    "    \n",
    "    return outputDataFrame\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    outputDataFrame=pd.DataFrame(columns=[\"Park\",\"Region\",\"Within Boundary\",\"<1mi Outside\",\"1-10mi Outside\",\n",
    "                                          \"10-100mi Outside\",\">100mi Outside\",\"Total Crashes\"])\n",
    "    \n",
    "    for park in range(len(ALLBOUNDARIES)): #for every park in the full set of boundaries \n",
    "        parkCode=ALLBOUNDARIES.loc[park][1] #take individual park code\n",
    "        \n",
    "        proj_park_crashes=crashChooser(ALLCRASHES,ALLBOUNDARIES,parkCode) #select park-specific crashes\n",
    "        proj_park_polygon=boundaryChooser(ALLCRASHES,ALLBOUNDARIES,parkCode) #select park-specific boundary(ies)\n",
    "        \n",
    "        output_df_park=proj_park_polygon.iloc[0][1] #select park code\n",
    "        output_df_region=str(proj_park_polygon.iloc[0][6])+\"R\" #select region code\n",
    "        \n",
    "        #Some AKR parks are recorded twice in an input dataset, must not record duplicates\n",
    "        \n",
    "        duplicate=output_df_park in outputDataFrame[\"Park\"].values\n",
    "        if duplicate==False:     \n",
    "        \n",
    "            if len(proj_park_crashes)==0: #if no crashes in a park, don't do spatial join calcs and add 0s to output df\n",
    "                outputDataFrame.loc[len(outputDataFrame.index)]=[output_df_park,output_df_region,0,0,0,0,0,0]\n",
    "            else:\n",
    "                outputDataFrame=calculations(proj_park_crashes, proj_park_polygon, outputDataFrame, output_df_park, output_df_region)\n",
    "            \n",
    "    #Output spreadsheet code here: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    outputDataFrame.to_excel(r\"C:\\Users\\Christopher.Dettmer\\Documents\\TSP\\Spatial Join Files\\All IMARS Crashes National and Region Coords Spatial Join Error Stats and Charts.xlsx\",\n",
    "                             sheet_name=\"Output Data\", index = False)\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833977de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
