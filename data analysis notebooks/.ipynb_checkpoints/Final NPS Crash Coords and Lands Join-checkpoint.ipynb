{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "006183d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If running in Anaconda/Jupyter Notebook, create a new anaconda environment and install geopandas, otherwise it won't run\n",
    "\n",
    "#Using NPS Lands Layer Package\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "    \n",
    "ALLCRASHES_ALLCOORDS = pd.read_csv(r\"C:\\Users\\Sophie.Kaye\\DOT OST\\volpe-proj-VU16A100 - Transportation Safety Program\\Region Briefing\\Data\\Output Data\\IMARS_slim_clean_allcoords_noAKR.csv\")\n",
    "ALLBOUNDARIES=gpd.read_file(r\"C:\\Users\\Sophie.Kaye\\DOT OST\\volpe-proj-VU16A100 - Transportation Safety Program\\Region Briefing\\Data\\GIS\\Other shapefiles\\nps_boundary.shp\")\n",
    "\n",
    "def NCR_Cleaner_ALLCOORDS(ALLCRASHES_ALLCOORDS):\n",
    "    \n",
    "    #This is the list of parks that (1) are not assigned the NACA label in the NPS Lands Boundary and\n",
    "    #(2) also have crashes with a park and coordinate filled; may not be entirely complete but should cover\n",
    "    #any parks that would be in the top 15 for the NCR\n",
    "    \n",
    "    nonNACAlist=[\"GWMP\",\"ROCR\",\"LINC\",\"MANA\",\"JEFM\",\"CATO\",\"PRWI\",\"CLBA\",\"THIS\",\"COGA\",\"FRDE\",\"GREE\",\n",
    "                 \"ANTI\",\"PAAV\",\"PISC\",\"MONO\",\"WHHO\",\"FOWA\",\"HAFE\",\"ARHO\",\"WOTR\",\"MLKM\",\"DDEM\",\"CHOH\",\n",
    "                 \"BEPA\",\"LYBA\",\"MALL\",\"MABE\",\"WWII\",\"FOTH\",\"WAMO\",\"KOWA\",\"FRDO\",\"CAWO\",\"VIVE\",\"WWIM\"]\n",
    "    \n",
    "    for crash in range(len(ALLCRASHES_ALLCOORDS)):\n",
    "        park=ALLCRASHES_ALLCOORDS.iloc[crash][47]\n",
    "        region=ALLCRASHES_ALLCOORDS.iloc[crash][48]\n",
    "        \n",
    "        if park not in nonNACAlist and region==\"NCR\":\n",
    "            ALLCRASHES_ALLCOORDS.iat[crash,47]=\"NACA\"\n",
    "            \n",
    "    return ALLCRASHES_ALLCOORDS\n",
    "\n",
    "\n",
    "def crashChooser_ALLCOORDS(ALLCRASHES_ALLCOORDS_CLEAN,ALLBOUNDARIES,parkCode):\n",
    "        \n",
    "    #Take park crashes, turn into a dataframe with coords, change from geometric to projected coords for sjoin\n",
    "    park_crashes_df=ALLCRASHES_ALLCOORDS_CLEAN.loc[ALLCRASHES_ALLCOORDS_CLEAN['Park']==parkCode]\n",
    "    park_crashes=gpd.GeoDataFrame(park_crashes_df, geometry=gpd.points_from_xy(park_crashes_df.LONGITUDE,park_crashes_df.LATITUDE))\n",
    "    proj_park_crashes=park_crashes.set_crs(epsg=3857)\n",
    "    \n",
    "    return proj_park_crashes\n",
    "\n",
    "def boundaryChooser_ALLCOORDS(ALLCRASHES_ALLCOORDS_CLEAN,ALLBOUNDARIES,parkCode):\n",
    "    \n",
    "    #Take park boundary(ies), change from geometric to projected coords for sjoin\n",
    "    park_polygon=ALLBOUNDARIES.loc[ALLBOUNDARIES['UNIT_CODE']==parkCode]\n",
    "    proj_park_polygon=park_polygon.set_crs(epsg=3857,allow_override=True)          \n",
    "        \n",
    "    return proj_park_polygon\n",
    "    \n",
    "\n",
    "def sjoin_0_ALLCOORDS(proj_park_crashes_clean, proj_park_polygon):\n",
    "    \n",
    "    return gpd.sjoin(proj_park_polygon,proj_park_crashes_clean,how='left')\n",
    "\n",
    "\n",
    "def sjoin_1_ALLCOORDS(proj_park_crashes_clean, proj_park_polygon):\n",
    "    \n",
    "    #Take park boundary(ies) with projected coords, add buffer, then reformat to geodataseries\n",
    "    park_polygon_1_buffer_geoseries=gpd.GeoSeries.buffer(proj_park_polygon,0.0145055773)\n",
    "    park_polygon_1_buffer=gpd.GeoDataFrame(geometry=gpd.GeoSeries(park_polygon_1_buffer_geoseries))\n",
    "\n",
    "    return gpd.sjoin(park_polygon_1_buffer,proj_park_crashes_clean,how='left')\n",
    "\n",
    "\n",
    "def sjoin_10_ALLCOORDS(proj_park_crashes_clean, proj_park_polygon):\n",
    "    \n",
    "    #Take park boundary(ies) with projected coords, add buffer, then reformat to geodataseries\n",
    "    park_polygon_10_buffer_geoseries=gpd.GeoSeries.buffer(proj_park_polygon,0.1450557739)\n",
    "    park_polygon_10_buffer=gpd.GeoDataFrame(geometry=gpd.GeoSeries(park_polygon_10_buffer_geoseries))\n",
    "\n",
    "    return gpd.sjoin(park_polygon_10_buffer,proj_park_crashes_clean,how='left')\n",
    "\n",
    "\n",
    "def sjoin_100_ALLCOORDS(proj_park_crashes_clean, proj_park_polygon):\n",
    "    \n",
    "    #Take park boundary(ies) with projected coords, add buffer, then reformat to geodataseries\n",
    "    park_polygon_100_buffer_geoseries=gpd.GeoSeries.buffer(proj_park_polygon,1.45055774)\n",
    "    park_polygon_100_buffer=gpd.GeoDataFrame(geometry=gpd.GeoSeries(park_polygon_100_buffer_geoseries))\n",
    "\n",
    "    return gpd.sjoin(park_polygon_100_buffer,proj_park_crashes_clean,how='left')\n",
    "\n",
    "\n",
    "def NoCoordsCleaner_ALLCOORDS(proj_park_crashes):\n",
    "\n",
    "    import numpy as np\n",
    "    \n",
    "    noCoords = 0\n",
    "    for i in range(len(proj_park_crashes)):\n",
    "        if np.isnan(proj_park_crashes.iloc[i]['LATITUDE']) or np.isnan(proj_park_crashes.iloc[i]['LONGITUDE']):\n",
    "            noCoords = noCoords + 1\n",
    "        else:\n",
    "            noCoords = noCoords \n",
    "    \n",
    "    #noCoords=0\n",
    "    \n",
    "    #for crash in range(len(proj_park_crashes)):\n",
    "        \n",
    "        #if pd.isnull(proj_park_crashes.iloc[crash][45])==True or pd.isnull(proj_park_crashes.iloc[crash][46])==True:    \n",
    "         #   noCoords+=1\n",
    "          #  #proj_park_crashes.drop(crash)\n",
    "            \n",
    "    return proj_park_crashes, noCoords\n",
    "    \n",
    "\n",
    "def calculations_ALLCOORDS(proj_park_crashes, proj_park_polygon, OutputDataFrame_AllCoords, output_df_park, output_df_region):\n",
    "    \n",
    "    proj_park_crashes_clean, noCoords=NoCoordsCleaner_ALLCOORDS(proj_park_crashes)\n",
    "    \n",
    "    within0=len(sjoin_0_ALLCOORDS(proj_park_crashes_clean, proj_park_polygon))\n",
    "    within1=len(sjoin_1_ALLCOORDS(proj_park_crashes_clean, proj_park_polygon))\n",
    "    within10=len(sjoin_10_ALLCOORDS(proj_park_crashes_clean, proj_park_polygon))\n",
    "    within100=len(sjoin_100_ALLCOORDS(proj_park_crashes_clean, proj_park_polygon))\n",
    "    \n",
    "    #Unable to drop crashes without coordinates in NoCoordsCleaner_ALLCOORDS, receiving errors\n",
    "    #Workaround by subtracting crashes without coordinates from crashes over 100 miles outside of park boundary\n",
    "    \n",
    "    totalCrashes=len(proj_park_crashes_clean)\n",
    "    over100=totalCrashes-within100-noCoords\n",
    "    over10=within100-within10\n",
    "    over1=within10-within1\n",
    "    over0=within1-within0\n",
    "    inBoundary=within0\n",
    "    #over100=totalCrashes-noCoords-over10-over1-over0-inBoundary\n",
    "    \n",
    "    OutputDataFrame_AllCoords.loc[len(OutputDataFrame_AllCoords.index)]=[output_df_park,output_df_region,inBoundary,over0,over1,over10,over100,noCoords,totalCrashes]\n",
    "    \n",
    "    return OutputDataFrame_AllCoords\n",
    "    \n",
    "    \n",
    "def main_ALLCOORDS():\n",
    "    \n",
    "    OutputDataFrame_AllCoords=pd.DataFrame(columns=[\"Park\",\"Region\",\"Within Boundary\",\"<1mi Outside\",\"1-10mi Outside\",\n",
    "                                          \"10-100mi Outside\",\">100mi Outside\",\"No Coordinates\",\"Total Crashes\"])\n",
    "    \n",
    "    ALLCRASHES_ALLCOORDS_CLEAN=NCR_Cleaner_ALLCOORDS(ALLCRASHES_ALLCOORDS)\n",
    "    \n",
    "    for park in range(len(ALLBOUNDARIES)): #for every park in the full set of boundaries \n",
    "        \n",
    "        parkCode=ALLBOUNDARIES.loc[park][1] #take individual park code\n",
    "        \n",
    "        proj_park_crashes=crashChooser_ALLCOORDS(ALLCRASHES_ALLCOORDS_CLEAN,ALLBOUNDARIES,parkCode) #select park-specific crashes\n",
    "        proj_park_polygon=boundaryChooser_ALLCOORDS(ALLCRASHES_ALLCOORDS_CLEAN,ALLBOUNDARIES,parkCode) #select park-specific boundary(ies)\n",
    "        \n",
    "        output_df_park=proj_park_polygon.iloc[0][1] #select park code\n",
    "        output_df_region=str(proj_park_polygon.iloc[0][6])+\"R\" #select region code\n",
    "        \n",
    "        #Some AKR parks are recorded twice in an input dataset, must not record duplicates\n",
    "        \n",
    "        duplicate=output_df_park in OutputDataFrame_AllCoords[\"Park\"].values\n",
    "        if duplicate==False:     \n",
    "        \n",
    "            if len(proj_park_crashes)==0: #if no crashes in a park, don't do spatial join calcs and add 0s to output df\n",
    "                \n",
    "                OutputDataFrame_AllCoords.loc[len(OutputDataFrame_AllCoords.index)]=[output_df_park,output_df_region,0,0,0,0,0,0,0]\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                OutputDataFrame_AllCoords=calculations_ALLCOORDS(proj_park_crashes, proj_park_polygon, OutputDataFrame_AllCoords, output_df_park, output_df_region)\n",
    "            \n",
    "    #Output spreadsheet here: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    OutputDataFrame_AllCoords = OutputDataFrame_AllCoords.sort_values(by=\"Park\")\n",
    "    OutputDataFrame_AllCoords.to_excel(r\"C:\\Users\\Sophie.Kaye\\DOT OST\\volpe-proj-VU16A100 - Transportation Safety Program\\Region Briefing\\Data\\Output Data\\Final Coordinate Stats and Charts AllCoords No AKR.xlsx\", sheet_name=\"Output Data\", index = False)\n",
    "    \n",
    "main_ALLCOORDS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa290b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLCRASHES_NOCOORDS = pd.read_csv(r\"C:\\Users\\Sophie.Kaye\\DOT OST\\volpe-proj-VU16A100 - Transportation Safety Program\\Region Briefing\\Data\\Output Data\\IMARS_slim_clean_noAKR.csv\")\n",
    "ALLBOUNDARIES=gpd.read_file(r\"C:\\Users\\Sophie.Kaye\\DOT OST\\volpe-proj-VU16A100 - Transportation Safety Program\\Region Briefing\\Data\\GIS\\Other shapefiles\\nps_boundary.shp\")\n",
    "\n",
    "def NCR_Cleaner_NOCOORDS(ALLCRASHES_NOCOORDS):\n",
    "    \n",
    "    #This is the list of parks that (1) are not assigned the NACA label in the NPS Lands Boundary and\n",
    "    #(2) also have crashes with a park and coordinate filled; may not be entirely complete but should cover\n",
    "    #any parks that would be in the top 15 for the NCR\n",
    "    \n",
    "    nonNACAlist=[\"GWMP\",\"ROCR\",\"LINC\",\"MANA\",\"JEFM\",\"CATO\",\"PRWI\",\"CLBA\",\"THIS\",\"COGA\",\"FRDE\",\"GREE\",\n",
    "                 \"ANTI\",\"PAAV\",\"PISC\",\"MONO\",\"WHHO\",\"FOWA\",\"HAFE\",\"ARHO\",\"WOTR\",\"MLKM\",\"DDEM\",\"CHOH\",\n",
    "                 \"BEPA\",\"LYBA\",\"MALL\",\"MABE\",\"WWII\",\"FOTH\",\"WAMO\",\"KOWA\",\"FRDO\",\"CAWO\",\"VIVE\",\"WWIM\"]\n",
    "    \n",
    "    for crash in range(len(ALLCRASHES_NOCOORDS)):\n",
    "        park=ALLCRASHES_NOCOORDS.iloc[crash][47]\n",
    "        region=ALLCRASHES_NOCOORDS.iloc[crash][48]\n",
    "        \n",
    "        if park not in nonNACAlist and region==\"NCR\":\n",
    "            ALLCRASHES_NOCOORDS.iat[crash,47]=\"NACA\"\n",
    "            \n",
    "    return ALLCRASHES_NOCOORDS\n",
    "\n",
    "\n",
    "def crashChooser_NOCOORDS(ALLCRASHES_NOCOORDS_CLEAN,ALLBOUNDARIES,parkCode):\n",
    "        \n",
    "    #Take park crashes, turn into a dataframe with coords, change from geometric to projected coords for sjoin\n",
    "    park_crashes_df=ALLCRASHES_NOCOORDS_CLEAN.loc[ALLCRASHES_NOCOORDS_CLEAN['Park']==parkCode]\n",
    "    park_crashes=gpd.GeoDataFrame(park_crashes_df, geometry=gpd.points_from_xy(park_crashes_df.LONGITUDE,park_crashes_df.LATITUDE))\n",
    "    proj_park_crashes=park_crashes.set_crs(epsg=3857)\n",
    "    \n",
    "    return proj_park_crashes\n",
    "\n",
    "def boundaryChooser_NOCOORDS(ALLCRASHES_NOCOORDS_CLEAN,ALLBOUNDARIES,parkCode):\n",
    "    \n",
    "    #Take park boundary(ies), change from geometric to projected coords for sjoin\n",
    "    park_polygon=ALLBOUNDARIES.loc[ALLBOUNDARIES['UNIT_CODE']==parkCode]\n",
    "    proj_park_polygon=park_polygon.set_crs(epsg=3857,allow_override=True)          \n",
    "        \n",
    "    return proj_park_polygon\n",
    "    \n",
    "\n",
    "def sjoin_0_NOCOORDS(proj_park_crashes_clean, proj_park_polygon):\n",
    "    \n",
    "    return gpd.sjoin(proj_park_polygon,proj_park_crashes_clean,how='left')\n",
    "\n",
    "\n",
    "def sjoin_1_NOCOORDS(proj_park_crashes_clean, proj_park_polygon):\n",
    "    \n",
    "    #Take park boundary(ies) with projected coords, add buffer, then reformat to geodataseries\n",
    "    park_polygon_1_buffer_geoseries=gpd.GeoSeries.buffer(proj_park_polygon,0.0145055773)\n",
    "    park_polygon_1_buffer=gpd.GeoDataFrame(geometry=gpd.GeoSeries(park_polygon_1_buffer_geoseries))\n",
    "\n",
    "    return gpd.sjoin(park_polygon_1_buffer,proj_park_crashes_clean,how='left')\n",
    "\n",
    "\n",
    "def sjoin_10_NOCOORDS(proj_park_crashes_clean, proj_park_polygon):\n",
    "    \n",
    "    #Take park boundary(ies) with projected coords, add buffer, then reformat to geodataseries\n",
    "    park_polygon_10_buffer_geoseries=gpd.GeoSeries.buffer(proj_park_polygon,0.1450557739)\n",
    "    park_polygon_10_buffer=gpd.GeoDataFrame(geometry=gpd.GeoSeries(park_polygon_10_buffer_geoseries))\n",
    "\n",
    "    return gpd.sjoin(park_polygon_10_buffer,proj_park_crashes_clean,how='left')\n",
    "\n",
    "\n",
    "def sjoin_100_NOCOORDS(proj_park_crashes_clean, proj_park_polygon):\n",
    "    \n",
    "    #Take park boundary(ies) with projected coords, add buffer, then reformat to geodataseries\n",
    "    park_polygon_100_buffer_geoseries=gpd.GeoSeries.buffer(proj_park_polygon,1.45055774)\n",
    "    park_polygon_100_buffer=gpd.GeoDataFrame(geometry=gpd.GeoSeries(park_polygon_100_buffer_geoseries))\n",
    "\n",
    "    return gpd.sjoin(park_polygon_100_buffer,proj_park_crashes_clean,how='left')\n",
    "\n",
    "\n",
    "def noCoordsCleaner_NOCOORDS(proj_park_crashes):\n",
    "\n",
    "    import numpy as np\n",
    "    \n",
    "    noCoords = 0\n",
    "    for i in range(len(proj_park_crashes)):\n",
    "        if np.isnan(proj_park_crashes.iloc[i]['LATITUDE']) or np.isnan(proj_park_crashes.iloc[i]['LONGITUDE']):\n",
    "            noCoords = noCoords + 1\n",
    "        else:\n",
    "            noCoords = noCoords \n",
    "    \n",
    "    #noCoords=0\n",
    "    \n",
    "    #for crash in range(len(proj_park_crashes)):\n",
    "        \n",
    "        #if pd.isnull(proj_park_crashes.iloc[crash][45])==True or pd.isnull(proj_park_crashes.iloc[crash][46])==True:    \n",
    "         #   noCoords+=1\n",
    "          #  #proj_park_crashes.drop(crash)\n",
    "            \n",
    "    return proj_park_crashes, noCoords\n",
    "    \n",
    "\n",
    "def calculations_NOCOORDS(proj_park_crashes, proj_park_polygon, OutputDataFrame_NoCoords, output_df_park, output_df_region):\n",
    "    \n",
    "    proj_park_crashes_clean, noCoords=noCoordsCleaner_NOCOORDS(proj_park_crashes)\n",
    "    \n",
    "    within0=len(sjoin_0_NOCOORDS(proj_park_crashes_clean, proj_park_polygon))\n",
    "    within1=len(sjoin_1_NOCOORDS(proj_park_crashes_clean, proj_park_polygon))\n",
    "    within10=len(sjoin_10_NOCOORDS(proj_park_crashes_clean, proj_park_polygon))\n",
    "    within100=len(sjoin_100_NOCOORDS(proj_park_crashes_clean, proj_park_polygon))\n",
    "    \n",
    "    #Unable to drop crashes without coordinates in noCoordsCleaner_NOCOORDS, receiving errors\n",
    "    #Workaround by subtracting crashes without coordinates from crashes over 100 miles outside of park boundary\n",
    "    \n",
    "    totalCrashes=len(proj_park_crashes_clean)\n",
    "    over100=totalCrashes-within100-noCoords\n",
    "    over10=within100-within10\n",
    "    over1=within10-within1\n",
    "    over0=within1-within0\n",
    "    inBoundary=within0\n",
    "    #over100=totalCrashes-noCoords-over10-over1-over0-inBoundary\n",
    "    \n",
    "    OutputDataFrame_NoCoords.loc[len(OutputDataFrame_NoCoords.index)]=[output_df_park,output_df_region,inBoundary,over0,over1,over10,over100,noCoords,totalCrashes]\n",
    "    \n",
    "    return OutputDataFrame_NoCoords\n",
    "    \n",
    "    \n",
    "def main_NOCOORDS():\n",
    "    \n",
    "    OutputDataFrame_NoCoords=pd.DataFrame(columns=[\"Park\",\"Region\",\"Within Boundary\",\"<1mi Outside\",\"1-10mi Outside\",\n",
    "                                          \"10-100mi Outside\",\">100mi Outside\",\"No Coordinates\",\"Total Crashes\"])\n",
    "    \n",
    "    ALLCRASHES_NOCOORDS_CLEAN=NCR_Cleaner_NOCOORDS(ALLCRASHES_NOCOORDS)\n",
    "    \n",
    "    for park in range(len(ALLBOUNDARIES)): #for every park in the full set of boundaries \n",
    "        \n",
    "        parkCode=ALLBOUNDARIES.loc[park][1] #take individual park code\n",
    "        \n",
    "        proj_park_crashes=crashChooser_NOCOORDS(ALLCRASHES_NOCOORDS_CLEAN,ALLBOUNDARIES,parkCode) #select park-specific crashes\n",
    "        proj_park_polygon=boundaryChooser_NOCOORDS(ALLCRASHES_NOCOORDS_CLEAN,ALLBOUNDARIES,parkCode) #select park-specific boundary(ies)\n",
    "        \n",
    "        output_df_park=proj_park_polygon.iloc[0][1] #select park code\n",
    "        output_df_region=str(proj_park_polygon.iloc[0][6])+\"R\" #select region code\n",
    "        \n",
    "        #Some AKR parks are recorded twice in an input dataset, must not record duplicates\n",
    "        \n",
    "        duplicate=output_df_park in OutputDataFrame_NoCoords[\"Park\"].values\n",
    "        if duplicate==False:     \n",
    "        \n",
    "            if len(proj_park_crashes)==0: #if no crashes in a park, don't do spatial join calcs and add 0s to output df\n",
    "                \n",
    "                OutputDataFrame_NoCoords.loc[len(OutputDataFrame_NoCoords.index)]=[output_df_park,output_df_region,0,0,0,0,0,0,0]\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                OutputDataFrame_NoCoords=calculations_NOCOORDS(proj_park_crashes, proj_park_polygon, OutputDataFrame_NoCoords, output_df_park, output_df_region)\n",
    "            \n",
    "    #Output spreadsheet here: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    OutputDataFrame_NoCoords = OutputDataFrame_NoCoords.sort_values(by=\"Park\")\n",
    "    OutputDataFrame_NoCoords.to_excel(r\"C:\\Users\\Sophie.Kaye\\DOT OST\\volpe-proj-VU16A100 - Transportation Safety Program\\Region Briefing\\Data\\Output Data\\Final Coordinate Stats and Charts No AKR.xlsx\", sheet_name=\"Output Data\", index = False)\n",
    "        \n",
    "main_NOCOORDS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9ee64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
